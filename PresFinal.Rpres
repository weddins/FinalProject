Final Presentation
========================================================
author: Bill Eddins
date: `r Sys.Date()`

This report presents an analysis of internet text files including blogs, news feeds and twitters to for a course in machine learning. See this link for more information [Data Science Specialization](https://www.coursera.org/specialization/jhudatascience/1?utm_source=catalog).  

There are two stated objectives for this project: a shiny app written in R which uses ngrams to guess a word and a presentation which describes the R program on RPubs.com. This app might run in any device with internet access. 

Building the Shiny App
========================================================

The Shiny App was built in two phases. The first phases resulted in an R app named `CreateTrigrams.R` that builds a list of trigrams. The second phase resulted in two apps: server.R and app.R. The reader can access the shiny app on shiny.io HERE. 

`CreateTrigrams.R` has the most sophisticated code and can be seen HERE. The reader should make note of `saveSubset`. It will be examined for optimization since it reads/writes text files. Other code preprocesses the text by removing email characters, removing numbers, converting text to lower case, and removing profane words. A special routine, `triGramTokenizer`, is created to control the functioning of the `TermDocumentMatix` statement. Finally, a file named `FreqTerms.csv` is generated to be used by the shiny app.  

Toward a Smarter Shiny App
========================================================
SwiftKey is interested in our apps because they develop internet apps. I propose that the shiny app should be supplemented with machine learning apps to determine when underlying topics in an internet feed change. `AnalyzeTextTopics.R` can be seen HERE. It's purpose is to monitor the number of topics and the log likelyhood which is an indication of goodness of fit. The graph to the right shows that the optimal number of topics is 6.

***
![alt text](Topics.png)

Optimizing the Shiny App
========================================================
Several R packages used for profiling were examined to determing bottlenecks. `Profile_R_micro.R` uses the `microbenchmark` package and can be found HERE. See the image below.

![alt text](saveSubsetTiming.png)

There are two functions named `saveSubset` and `saveSubsetRODBC` which were profilled using `microbenchmark`.  `saveSubset` is written in base R. It took on aveage 45.2 microseconds to execute. `saveSubsetRODBC` uses the RDOBC package and MS SQL Server. It took on average 15.4 micoseconds to execute. Almost 3 times faster!

In Summary
========================================================
Several R code segments were written to create and analyze the output of the final apps. If SwiftKey is interested, an R package can be made that can be used in their operations to analyze internet text to determine if topics change or to optimize the code to run faster. Following are links to the code.

- `CreateTrigrams.R`
- The Shiny app
  - server.R
  - ui.R
- `AnalyzeTextTopics.R`
- `Profile_R_micro.R`
